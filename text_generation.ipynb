{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation Project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Write an abstract here, dude. </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we'll be building a text generator that will be able to generate fake Amazon product reviews that will, hopefully, be indistinguishable from normal, everyday reviews left by actual human beings.  This is, by no means, meant to be for fraudulent uses.  This is an excercise in generating believable text and we were fortunate enough to have a large dataset of Amazon reviews to experiement with. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T19:39:04.951589Z",
     "start_time": "2021-02-03T19:39:04.937814Z"
    }
   },
   "outputs": [],
   "source": [
    "# The usuals\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import re\n",
    "\n",
    "# NLTK stuff\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Tensorflow stuff\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.python.keras import utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP Functions\n",
    "\n",
    "def remove_url(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r\"\", text)\n",
    "\n",
    "\n",
    "def remove_n(text):\n",
    "    n = re.compile(r'\\n')\n",
    "    return n.sub(r'', text)\n",
    "\n",
    "\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(pattern = \n",
    "    \"[\"\n",
    "    u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "    u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "    u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "    u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "    \"]+\",\n",
    "    flags = re.UNICODE\n",
    "    )\n",
    "    return emoji_pattern.sub(r\"\", string)\n",
    "\n",
    "\n",
    "def clean_text(text_column):\n",
    "    text_column = text_column.apply(lambda x: remove_url(x))\n",
    "    text_column = text_column.apply(lambda x: remove_n(x))\n",
    "    text_column = text_column.apply(lambda x: remove_emoji(x))\n",
    "    return text_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T19:39:18.751532Z",
     "start_time": "2021-02-03T19:39:05.064476Z"
    }
   },
   "outputs": [],
   "source": [
    "appliances_df = pd.read_json('Appliances.json', lines = True)\n",
    "print(appliances_df.shape)\n",
    "appliances_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T19:39:19.313889Z",
     "start_time": "2021-02-03T19:39:18.754721Z"
    }
   },
   "outputs": [],
   "source": [
    "# Checking for null values....since we can see them already in several columns\n",
    "\n",
    "appliances_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T19:39:19.372585Z",
     "start_time": "2021-02-03T19:39:19.317045Z"
    }
   },
   "outputs": [],
   "source": [
    "# We can get rid of most of these columns since they aren't relevant to this project\n",
    "\n",
    "drop_columns = ['overall', 'vote', 'verified', 'reviewTime', 'reviewerID',\n",
    "                'asin', 'style', 'unixReviewTime', 'image', 'reviewerName']\n",
    "\n",
    "appliances_df.drop(drop_columns, axis = 1, inplace = True)\n",
    "\n",
    "print(appliances_df.shape)\n",
    "appliances_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T19:41:02.106827Z",
     "start_time": "2021-02-03T19:39:19.511198Z"
    }
   },
   "outputs": [],
   "source": [
    "# for i in appliances_df['summary']:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Not really sure what to do with the summary column just yet, so we'll leave this as-is for now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrubbing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T19:41:02.258557Z",
     "start_time": "2021-02-03T19:41:02.109292Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's check the null values again\n",
    "\n",
    "appliances_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T19:41:02.621904Z",
     "start_time": "2021-02-03T19:41:02.261175Z"
    }
   },
   "outputs": [],
   "source": [
    "# We can drop the rows with null values since they represent a very small percentage of data\n",
    "# Also...can't do much with ones that don't have reviews.  \n",
    "\n",
    "appliances_df.dropna(inplace = True)\n",
    "appliances_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T19:42:44.495152Z",
     "start_time": "2021-02-03T19:41:02.627327Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in appliances_df['reviewText']:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T19:42:56.558762Z",
     "start_time": "2021-02-03T19:42:44.623647Z"
    }
   },
   "outputs": [],
   "source": [
    "# Running several functions for cleaning text\n",
    "\n",
    "appliances_df['reviewText'] = appliances_df['reviewText'].apply(lambda x: remove_url(x))\n",
    "appliances_df['reviewText'] = appliances_df['reviewText'].apply(lambda x: remove_n(x))\n",
    "appliances_df['reviewText'] = appliances_df['reviewText'].apply(lambda x: remove_emoji(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T19:42:56.583522Z",
     "start_time": "2021-02-03T19:42:56.573871Z"
    }
   },
   "outputs": [],
   "source": [
    "# Checking to make sure this worked\n",
    "\n",
    "appliances_df['reviewText'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T19:43:01.140376Z",
     "start_time": "2021-02-03T19:42:56.586345Z"
    }
   },
   "outputs": [],
   "source": [
    "appliances_df['summary'] = clean_text(appliances_df['summary'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T19:43:01.149680Z",
     "start_time": "2021-02-03T19:43:01.143010Z"
    }
   },
   "outputs": [],
   "source": [
    "appliances_df['summary'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T19:43:18.901712Z",
     "start_time": "2021-02-03T19:43:18.890100Z"
    }
   },
   "outputs": [],
   "source": [
    "appliances_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
